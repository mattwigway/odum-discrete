---
title: Introduction to discrete choice models in R
author: Matt Bhagat-Conway
date: August 11, 2022
institute: Odum Institute<br/>University of North Carolina at Chapel Hill
format:
    revealjs:
        theme: [default, datamatters.scss]
        width: 1280
        height: 720
        logo: dm-logo.png
execute:
    cache: true
bibliography: discrete-choice.bib
---

## About me

```{r}
#| echo: false
#| cache: false
system2("julia", c("extract_chunks.jl", "discrete-choice.qmd"))
```

```{r}
#| include=FALSE
library(ggplot2)
bgcolor = "#002e3e"
fgcolor = "#ffffff"
linecolor = "#ff0948"

theme_dm = function () {
    return(theme_minimal() + theme(
    panel.background=element_rect(fill=bgcolor, color=fgcolor),
    panel.grid=element_blank(),
    plot.background=element_rect(fill=bgcolor, size=0),
    axis.text=element_text(size=10, color=fgcolor),
    axis.title=element_text(size=14, color=fgcolor))
)}

update_geom_defaults("point", list(color=linecolor))
update_geom_defaults("line", list(color=linecolor))
update_geom_defaults("col", list(color=linecolor, fill=linecolor))

library(knitr)

clear = function () {
    rm(list=setdiff(ls(), c("theme_dm", "fgcolor", "bgcolor", "linecolor", "clear")))
    update_geom_defaults("point", list(color=linecolor))
    update_geom_defaults("line", list(color=linecolor))
    update_geom_defaults("col", list(color=linecolor, fill=linecolor))
}
```

- Assistant professor of City and Regional Planning
- Research focus: transportation modeling and simulation
    - Heavy use of discrete choice models
- PhD in Geography from Arizona State
- Three years experience as transportation modeling software developer

## Before we go any further

- Slides, code, and data at [https://projects.indicatrix.org/odum-discrete/](https://projects.indicatrix.org/odum-discrete/)

## Before we go any further

- If you haven't already installed R, RStudio, `apollo`, and `tidyverse`, do so now
- R: [https://r-project.org](https://r-project.org)
- RStudio: [https://rstudio.com](https://rstudio.com)
- `apollo` and `tidyverse`: in RStudio console, run:
```r
install.packages("tidyverse")
install.packages("apollo")
```

## What are discrete choice models?

- Any model of a variable that takes on discrete values
- Could be binary (two values), categorical (more than two values), or quantized (e.g., integers)

## Types of discrete choice models

- Random utility models
    - Logistic regression, multinomial logistic regression, ordered logit, mixed logit
- Count models
    - Poisson and negative binomial regression
- Machine learning
    - Random forests, support vector machines, _k_ nearest neighbors

## Random utility theory

- Individuals are maximizing the _utility_ of their choices
- Utility is an abstract concept of value
- Individuals choose the choice with the highest utility
- Utility is random because there is a random component to utility
- We won't know which choice is the highest utility for an individual, only the probabilities that a particular choice will have the highest utility

# Binary logistic regression

## Binary logistic regression

- A very common model for binary (yes/no) outcomes
- Probably familiar to many
- Usually presented as a generalized linear model

## Binary logistic regression: Intuition

- Linear functions can take on any value
- Probabilities need to be between 0 and 1
- The logit function transforms arbitrary linear values to (0, 1)

## Binary logistic regression: the math

$$
y^* = \alpha + \beta_1 x_1 + \beta_2 x_2 \cdots + \epsilon
$$

$$
\epsilon \thicksim \mathrm{Logistic}
$$
$$
p(y = 1) = p(y^* > 0) = \frac{e^{y^*}}{1 + e^{y^*}}
$$


## The logit function

<!-- run logistic regression -->
```{r}
#| fig-alt: Logistic regression, showing sigmoid function
#| dev: svg
#| fig-width: 6
#| fig-height: 3
#| out-width: 1200px
#| fig-align: center
library(ggplot2)

xs = seq(-5.5, 5.5, 0.1)
ys = exp(xs) / (1 + exp(xs))

data = data.frame(x=xs, y=ys)

ggplot(data, aes(x=x, y=y)) +
    theme_dm() +
    geom_line() +
    xlab("Utility") +
    ylab("Probability") +
    coord_cartesian(xlim=c(-5, 5))

```

## Logistic regression in R

`nhts-carpool-glm.R`

```{r}
#| echo: true
#| output: false
#| filename: nhts-carpool-glm.R
library(tidyverse)

data = read_csv("data/nhts/carpool.csv")

glm_model = glm(carpool~hhsize+cars_per_driver+commute+social,
    family=binomial(link="logit"), data)
summary(glm_model)
```

## Logistic regression in R

```{r}
summary(glm_model)
```

## Binary logistic regression as a random utility model

- We can treat the linear predictor in logistic regression as the utility of the modeled outcome
- In this case, the utility of carpooling
- We also need a utility of not carpooling
- Decisionmakers will choose the highest utility _alternative_

## Binary logistic regression as a random utility model

- Utilities are only meaningful relative to each other
- Usual practice is to set utility of one alternative to 0

## Binary logistic regression as a random utility model

$$
y^* = \alpha + \beta_1 x_1 + \beta_2 x_2 \cdots + \epsilon
$$
$$
p(y = 1) = p(y^* > 0)\\= \frac{e^{y^*}}{1 + e^{y^*}}
$$



## Binary logistic regression as a random utility model

$$
U_{y=1} = \alpha + \beta_1 x_1 + \beta_2 x_2 \cdots + \epsilon_1
$$
$$
U_{y=0} = 0 + \epsilon_0
$$

$$
p(y = 1) = p(U_{y=1} > U_{y=0})\\= \frac{e^{U_{y=1}}}{e^{U_{y=0}} + e^{U_{y=1}}}
$$

## Binary logistic regression as a random utility model in R

```{r}
#| include: false
rm(list=setdiff(ls(), c("glm_model", "theme_dm", "clear", "fgcolor", "bgcolor", "linecolor"))) # clean environment, keep glm model for comparison
```

`nhts-carpool-apollo.R`
```{r}
#| echo: true
#| filename: nhts-carpool-apollo.R
library(apollo)
library(tidyverse)

# Read data - variable must be called "database"
database = read_csv("data/nhts/carpool.csv")
```

---

```{r}
#| echo: true
#| filename: nhts-carpool-apollo.R

# Initialize Apollo library
apollo_initialise()

# set parameters for overall model
apollo_control = list(
    modelName="Carpool_binary",
    indivID="id"
)
```

---


```{r}
#| echo: true
#| filename: nhts-carpool-apollo.R


# In Apollo, you specify your utility functions by hand,
# first telling Apollo what coefficients to estimate
apollo_beta = c(
    constant_carpool = 0, # 0 is starting value
    b_hhsize = 0,
    b_cars_per_driver = 0,
    b_commute = 0,
    b_social = 0
)

# any parameters that you want to remain constant go here
apollo_fixed = c()
```

---

```{r}
#| echo: true
#| filename: nhts-carpool-apollo.R

# prepare the inputs to the Apollo estimation code
apollo_inputs = apollo_validateInputs()
```

---


```{r}
#| echo: true
#| filename: nhts-carpool-apollo.R

# this function calculates probabilities of each alternative
apollo_probabilities = function(apollo_beta, apollo_inputs,
        functionality="estimate") {
    # so we can refer to variables by name
    apollo_attach(apollo_beta, apollo_inputs)
    on.exit(apollo_detach(apollo_beta, apollo_inputs))

    # This is the list of probabilities for the alternatives
    # for each observation
    P = list()

    # Define utility functions
    V = list()
    V[["carpool"]] = constant_carpool + b_hhsize * hhsize +
        b_cars_per_driver * cars_per_driver +
        b_commute * commute + b_social * social
    V[["not_carpool"]] = 0

    # associate utility functions with data
    logit_settings = list(
        alternatives = c(carpool=T, not_carpool=F),
        avail        = list(carpool=T, not_carpool=T),
        choiceVar    = carpool,
        utilities    = V
    )

    # compute probabilities
    P[["model"]] = apollo_mnl(logit_settings, functionality)

    P = apollo_prepareProb(P, apollo_inputs, functionality)
    return(P)
}
```

---

```{r}
#| echo: true
#| filename: nhts-carpool-apollo.R

# finally, estimate the model
model = apollo_estimate(apollo_beta, apollo_fixed,
    apollo_probabilities, apollo_inputs)
```

---

```{r}
#| echo: true
#| filename: nhts-carpool-apollo.R

# print results
apollo_modelOutput(model)
```

## But don't take my word for it...

```{r}
#| echo: false
summary(glm_model)
```

# Questions?

# The multinomial logit model

## What about more than two outcomes?

- Random utility theory doesn't constrain us to two outcomes
- We can have many outcomes, and decisionmakers choose the one with the highest utility
- This is known as a _multinomial_ model

## Extending logistic regression to the multinomial case

- Instead of two utilities $U_{y=1}$ and $U_{y=0}$, we have arbitrary number of utility functions $U_i$
- Decisionmakers choose the option with the highest utility
- As with binary logistic regression, utility functions are usually linear combinations of parameters

## Multinomial logistic regression: the math

- Probability then becomes

$$
p(y=i)\\= p(U_i > \mathrm{all~other}~U)\\
    =\frac{e^{U_i}}{e^{U_1} + e^{U_2} \cdots}\\
    =\frac{e^{U_i}}{\sum_{j \in I} e^{U_j}}
$$

## Multinomial logistic regression in R

```{r}
#| include: false
clear()
```

- We will build a model of working from home expectation post-pandemic, using data from the [COVID Future](https://covidfuture.org) study.
- We will estimate four utility functions, for being unable to, rarely, frequently, and always working from home
- Based on age, income, and job type

## Multinomial logistic regression in R
`
- These utility functions will have the same variables but different coefficients
- Each will also have a _alternative specific constant_---like a constant in logistic regression that represents the base rate, but for each alternative
- One utility function will be held at zero

## Multinomial logistic regression in R

`covidfuture-wfh-mnl.R`

```{r}
#| echo: true
#| filename: covidfuture-wfh-mnl.R
library(apollo)
library(tidyverse)

database = read_csv("data/covidfuture_wfh.csv")

apollo_initialise()

apollo_control = list(
    modelName="WFH_Postpandemic",
    indivID="resp_id"
)
```

---

```{r}
#| echo: true
#| filename: covidfuture-wfh-mnl.R

head(database)
```

---

```{r}
#| echo: true
#| filename: covidfuture-wfh-mnl.R

# now, we must define all the coefficients
# we have separate sets of coefficients for each utility
# function, because the utilities need to be different
apollo_beta = c(
    asc_rarely = 0,
    asc_often = 0,
    asc_always = 0,
    b_rarely_age = 0,
    b_often_age = 0,
    b_always_age = 0,
    b_rarely_highinc = 0,
    b_often_highinc = 0,
    b_always_highinc = 0,
    b_rarely_service_worker = 0,
    b_often_service_worker = 0,
    b_always_service_worker = 0
)
```
---

```{r}
#| echo: true
#| filename: covidfuture-wfh-mnl.R

apollo_fixed = c()

apollo_inputs = apollo_validateInputs()
```

---

```{r}
#| echo: true
#| filename: covidfuture-wfh-mnl.R

# Finally, we define the utility functions in apollo_probabilities
apollo_probabilities = function(apollo_beta, apollo_inputs,
        functionality="estimate") {
    apollo_attach(apollo_beta, apollo_inputs)
    on.exit(apollo_detach(apollo_beta, apollo_inputs))

    P = list()

    # define utility functions
    V = list()
    # fix one utility to zero
    V[["Unable"]] = 0
    V[["Rarely"]] = asc_rarely + b_rarely_age * age +
        b_rarely_highinc * income_100k_plus +
        b_rarely_service_worker * service_worker
    V[["Often"]] = asc_often + b_often_age * age +
        b_often_highinc * income_100k_plus +
        b_often_service_worker * service_worker
    V[["Always"]] = asc_always + b_always_age * age +
        b_always_highinc * income_100k_plus +
        b_always_service_worker * service_worker
        
    mnl_settings = list(
        alternatives = c(Unable="Unable", Rarely="Rarely",
            Often="Often", Always="Always"),
        avail = list(Unable=T, Rarely=T, Often=T, Always=T),
        choiceVar = wfh,
        utilities = V
    )

    P[["model"]] = apollo_mnl(mnl_settings, functionality)
    P = apollo_prepareProb(P, apollo_inputs, functionality)
    return(P)
}
```

---

```{r}
#| echo: true
#| filename: covidfuture-wfh-mnl.R

# estimate model
model = apollo_estimate(apollo_beta, apollo_fixed,
    apollo_probabilities, apollo_inputs)
```

---

```{r}
#| echo: true
#| filename: covidfuture-wfh-mnl.R

# Print results
apollo_modelOutput(model)
```

## Interpreting multinomial logit results

```{r}
df = data.frame(
        round(matrix(model$estimate, 4, 3, byrow=T), digits=2),
        row.names=c("ASC", "Age", "High income", "Service worker")
)
names(df) <- c("Rarely", "Often", "Always")
kable(df)
```

Note: all variables significant at $p < 0.05$

---

- Relative to being unable to WFH,
    - Older people are less likely to WFH rarely or often, but more likely to always
    - Higher income people are much more likely to be able to and choose to WFH
    - Service workers are less likely to be able to WFH
    - Scale of age variable is different from others

## Questions?

## Specifying a multinomial logit model

- Multinomial logit models can have independent variables that vary at the individual level (e.g., income)
- Can also have variables at the alternative level (e.g., travel time)
- Utilities identified only up to a constant offset
    - Constant changes to all utilities does not change outcome

## Specifying a multinomial logit model
- Variables that vary at _individual_ level must have different coefficients for each alternative, and one must be zero
- Variables that vary at _alternative_ level may or may not have different coefficients for each alternative, and there is no need have one zero coefficient
    - But you do have to know values for unchosen alternatives

## Specifying a multinomial logit model

```{dot}
//| fig-width: 12
//| fig-height: 6

digraph G{
    bgcolor = "#00000000";
    node [color = "#ffffff", fontcolor = "#ffffff"];
    edge [color = "#ffffff"];

    inc [label=Income, shape=box];
    subgraph clustertt {
        color = "#00000000";
    ttw [label="Travel time of walk", shape=box];
    ttb [label="Travel time of bus", shape=box];
    ttc [label="Travel time of car", shape=box];
    }

    uw [label = "Utility of walk"];
    ub [label = "Utility of bus"];
    uc [label = "Utility of car"];

    edge [arrowhead = none];
    node [shape = none, label = "", margin=0, width=0, height=0];
    inc -> iw;
    inc -> ib;
    inc -> ic;
    ttw -> tw;
    ttb -> tb;
    ttc -> tc;

    edge [arrowhead = normal];
    iw -> uw;
    ib -> ub;
    ic -> uc;
    tw -> uw;
    tb -> ub;
    tc -> uc;

    edge [color="#ff0948", arrowhead=none];
    node [color="#ff0948", shape=none, fontcolor="#ff0948"];
    md [label = "Must be different,\none must be zero"];
    cs [label = "Can be same"];

    iw -> md;
    ic -> md;
    ib -> md;

    cs -> tw;
    cs -> tb;
    cs -> tc;

}
```

## Estimating a multinomial logit model in R

```{r}
#| echo: false
clear()
```

- We're going to build a multinomial logit mode choice model of intercity mode choice
- Data from Apollo examples

## The data

```{r}
#| echo: false
kable(read_csv("data/modechoice_apollo.csv", n_max=6))
```

```{r}
#| include: false
clear()
```

## Estimation in R

`mode-choice-mnl.R`

```{r}
#| echo: true
#| filename: mode-choice-mnl.R

library(apollo)
library(tidyverse)

database = read_csv("data/modechoice_apollo.csv")

apollo_initialise()

apollo_control = list(
    modelName = "Apollo_Mode_Choice",
    indivID="ID"
)
```

---

```{r}
#| echo: true
#| filename: mode-choice-mnl.R
head(database)
```

---

```{r}
#| echo: true
#| filename: mode-choice-mnl.R

apollo_beta = c(
    asc_air = 0,
    asc_bus = 0,
    asc_rail = 0,
    # leaving out an asc_car as base category
    b_cost = 0,
    b_access_time = 0,
    b_in_vehicle_time = 0,
    # income is an individual level variable, so
    # must be different for different alternatives
    b_income_air = 0,
    b_income_bus = 0,
    b_income_rail = 0
)
```

---

```{r}
#| echo: true
#| filename: mode-choice-mnl.R

apollo_fixed = c()

apollo_inputs = apollo_validateInputs()
```

---

```{r}
#| echo: true
#| filename: mode-choice-mnl.R

apollo_probabilities = function(apollo_beta, apollo_inputs,
        functionality="estimate") {
    apollo_attach(apollo_beta, apollo_inputs)
    on.exit(apollo_detach(apollo_beta, apollo_inputs))

    P = list()

    # define utility functions
    V = list()
    # We can include cost and in-vehicle time here because they vary over
    # alternatives
    V[["car"]] = b_cost * cost_car +
        b_in_vehicle_time * time_car

    V[["air"]] = asc_air +
        b_cost * cost_air +
        b_in_vehicle_time * time_air +
        b_access_time * access_air +
        b_income_air * income

    V[["rail"]] = asc_rail +
        b_cost * cost_rail +
        b_in_vehicle_time * time_rail +
        b_access_time * access_rail +
        b_income_rail * income

    V[["bus"]] = asc_bus +
        b_cost * cost_bus +
        b_in_vehicle_time * time_bus +
        b_access_time * access_bus +
        b_income_bus * income

    mnl_settings = list(
        alternatives = c(car=1, air=3, rail=4, bus=2),
        avail = list(car=av_car, air=av_air, rail=av_rail, bus=av_bus),
        choiceVar = choice,
        utilities = V
    )

    P[["model"]] = apollo_mnl(mnl_settings, functionality)

    # For panel data, this multiplies observations for single individuals
    # together - no effect in multinomial logit but still required.
    P = apollo_panelProd(P, apollo_inputs, functionality)
    P = apollo_prepareProb(P, apollo_inputs, functionality)
    return(P)
}
```

---

```{r}
#| echo: true
#| filename: mode-choice-mnl.R

# estimate model
model = apollo_estimate(apollo_beta, apollo_fixed,
    apollo_probabilities, apollo_inputs)
```

---

```{r}
#| echo: true
#| filename: mode-choice-mnl.R

# Print results
apollo_modelOutput(model)
```

---

```{r}
#| echo: true
#| filename: mode-choice-mnl.R

# save results in current directory,
# using model name specified above
apollo_saveOutput(model)
```

## Valuation using discrete choice models

- A common use for discrete choice models is to calculate willingness-to-pay
- The linear-in-parameters utility function puts everything in terms of utility
- If we have a cost parameter, we can use the model to put everything else in monetary units

## Valuation using discrete choice models

- The coefficients of the model are how much of `x` one unit of utility is worth
    - i.e. partial derivatives of utility with respect to `x`
- We want value of time, i.e. dollars / hour
- Travel time coefficient is utility / minute
- Cost coefficient is utility / dollar
- If $u$ is utility, $c$ is cost, and $t$ is in-vehicle time,
$\frac{\beta_t}{\beta_{c}} = \frac{\frac{\delta u}{\delta t}}{\frac{\delta u}{\delta c}} = \frac{\delta c}{\delta t}$

## Valuation using discrete choice models

```{r}
#| include: false
bc = round(model$estimate[["b_cost"]], digits=4)
bt = round(model$estimate[["b_in_vehicle_time"]], digits=4)
vtt = round(model$estimate[["b_in_vehicle_time"]] / model$estimate[["b_cost"]], digits=3)
```

$$\beta_c = `r bc`$$
$$\beta_t = `r bt`$$

$$ \frac{\beta_t}{\beta_c} = \frac{`r bt`}{`r bc`} = {£`r vtt`}/\mathrm{minute} = {£`r vtt * 60`}/\mathrm{hour} $$

## Confidence intervals for valuation

- We can use the Delta method to calculate standard errors for combinations of parameters [@daly_estimating_2020]
- Implemented in Apollo using `apollo_deltaMethod` function

---

```{r}
#| echo: true
#| filename: mode-choice-mnl.R

apollo_deltaMethod(model, deltaMethod_settings=list(
    expression="b_in_vehicle_time * 60 / b_cost"
))
```

## Exercise

- People may value in-vehicle time differently on the train vs. plane vs. car vs. bus
- Modify the model to estimate separate in-vehicle time coefficients for each mode, and calculate willingness-to-pay for each
- (One) answer in mode-choice-mnl-in-vehicle-answers.R

## Solution

```{r}
#| include: false
clear()
```

```{r}
#| include: false
#| filename: mode-choice-mnl-in-vehicle-answers.R

library(apollo)
library(tidyverse)

database = read_csv("data/modechoice_apollo.csv")

apollo_initialise()

apollo_control = list(
    modelName = "Apollo_Mode_Choice_Flexible",
    indivID="ID"
)

head(database)

```


```{r}
#| echo: true
#| filename: mode-choice-mnl-in-vehicle-answers.R

apollo_beta = c(
    asc_air = 0,
    asc_bus = 0,
    asc_rail = 0,
    # leaving out an asc_car as base category
    b_cost = 0,
    b_access_time = 0,
    b_in_vehicle_time_air = 0,
    b_in_vehicle_time_bus = 0,
    b_in_vehicle_time_car = 0,
    b_in_vehicle_time_rail = 0,
    # income and party_size are individual level variable, so
    # must be different for different alternatives
    b_income_air = 0,
    b_income_bus = 0,
    b_income_rail = 0
)
```

---

```{r}
#| include: false
#| filename: mode-choice-mnl-in-vehicle-answers.R

apollo_fixed = c()

apollo_inputs = apollo_validateInputs()
```

```{r}
#| echo: true
#| filename: mode-choice-mnl-in-vehicle-answers.R

apollo_probabilities = function(apollo_beta, apollo_inputs,
        functionality="estimate") {
    apollo_attach(apollo_beta, apollo_inputs)
    on.exit(apollo_detach(apollo_beta, apollo_inputs))

    P = list()

    # define utility functions
    V = list()
    # We can include cost and in-vehicle time here because they vary over
    # alternatives
    V[["car"]] = b_cost * cost_car +
        b_in_vehicle_time_car * time_car

    V[["air"]] = asc_air +
        b_cost * cost_air +
        b_in_vehicle_time_air * time_air +
        b_access_time * access_air +
        b_income_air * income

    V[["rail"]] = asc_rail +
        b_cost * cost_rail +
        b_in_vehicle_time_rail * time_rail +
        b_access_time * access_rail +
        b_income_rail * income

    V[["bus"]] = asc_bus +
        b_cost * cost_bus +
        b_in_vehicle_time_bus * time_bus +
        b_access_time * access_bus +
        b_income_bus * income

    mnl_settings = list(
        alternatives = c(car=1, air=3, rail=4, bus=2),
        avail = list(car=av_car, air=av_air, rail=av_rail, bus=av_bus),
        choiceVar = choice,
        utilities = V
    )

    P[["model"]] = apollo_mnl(mnl_settings, functionality)

    # For panel data, this multiplies observations for single individuals
    # together - no effect in multinomial logit but still required.
    P = apollo_panelProd(P, apollo_inputs, functionality)
    P = apollo_prepareProb(P, apollo_inputs, functionality)
    return(P)
}
```

---

```{r}
#| echo: true
#| filename: mode-choice-mnl-in-vehicle-answers.R

# estimate model
model = apollo_estimate(apollo_beta, apollo_fixed,
    apollo_probabilities, apollo_inputs)
```

---

```{r}
#| echo: true
#| filename: mode-choice-mnl-in-vehicle-answers.R

# Print results
apollo_modelOutput(model)
```

---

```{r}
#| echo: true
#| filename: mode-choice-mnl-in-vehicle-answers.R

# save results in current directory,
# using model name specified above
apollo_saveOutput(model)
```

---

```{r}
#| echo: true
#| filename: mode-choice-mnl-in-vehicle-answers.R


apollo_deltaMethod(model, deltaMethod_settings=list(
    expression="b_in_vehicle_time_car * 60 / b_cost"
))
```

---

```{r}
#| echo: true
#| filename: mode-choice-mnl-in-vehicle-answers.R


apollo_deltaMethod(model, deltaMethod_settings=list(
    expression="b_in_vehicle_time_air * 60 / b_cost"
))
```

---

```{r}
#| echo: true
#| filename: mode-choice-mnl-in-vehicle-answers.R


apollo_deltaMethod(model, deltaMethod_settings=list(
    expression="b_in_vehicle_time_bus * 60 / b_cost"
))
```

---

```{r}
#| echo: true
#| filename: mode-choice-mnl-in-vehicle-answers.R


dm = apollo_deltaMethod(model, deltaMethod_settings=list(
    expression="b_in_vehicle_time_rail * 60 / b_cost"
))
```

## Interpretation

```{r}
#| include: false
car_vtt = apollo_deltaMethod(model, deltaMethod_settings=list(
    operation="ratio",
    parName1="b_in_vehicle_time_car",
    parName2="b_cost",
    multPar1=60
))[1,1]

air_vtt = apollo_deltaMethod(model, deltaMethod_settings=list(
    operation="ratio",
    parName1="b_in_vehicle_time_air",
    parName2="b_cost",
    multPar1=60
))[1,1]

bus_vtt = apollo_deltaMethod(model, deltaMethod_settings=list(
    operation="ratio",
    parName1="b_in_vehicle_time_bus",
    parName2="b_cost",
    multPar1=60
))[1,1]

rail_vtt = apollo_deltaMethod(model, deltaMethod_settings=list(
    operation="ratio",
    parName1="b_in_vehicle_time_rail",
    parName2="b_cost",
    multPar1=60
))[1,1]

df = tibble(lab=c("Car", "Air", "Bus", "Rail"), vtt=c(car_vtt, air_vtt, bus_vtt, rail_vtt))
```

```{r}
#| fig-alt: Bar plot of values of travel time for car, air, bus, and rail
#| dev: svg
#| fig-width: 6
#| fig-height: 3
#| out-width: 1200px
#| fig-align: center

ggplot(df, aes(x=lab, y=vtt)) +
    theme_dm() +
    geom_col() +
    xlab("") +
    ylab("Value of travel time (£/hour)")

```

- People really don't like being on airplanes

## Correlation does not imply causation

[![XKCD cartoon demonstrating that correlation does not imply causation](correlation_2x.png)](https://xkcd.com/552/)

## Correlation does not imply causation

- Of course we can't interpret model coefficients as causal
- Valuation estimates are derived from coefficients
- Any bias in coefficients may affect valuation

## Correlation does not imply causation

- Often, prices will be correlated with unobserved positive aspects, biasing the value of time down
    - For example, legroom or class of service in the air travel case
- Other variable may be biased too
    - We don't have number of connections in our model. How might this bias the value of time for air travel?

## Questions?

# Predictions and market shares

- Often, you will want to use your model to make some prediction
- For example, maybe we want to reduce use of air travel for climate reasons, so we decide to add a £25 tax
- Mathematically, we can use the formulas above to calculate probabilities for any 
- We can use the `apollo_prediction` function to do predictions within Apollo

## Predictions and market shares in R

```{r}
#| include: false
#| filename: prediction.R

# Run this file after running mode-choice-mnl-in-vehicle-answers.R
```

```{r}
#| echo: true
#| filename: prediction.R

# Make predictions for the existing dataset
predictions =
    apollo_prediction(model, apollo_probabilities, apollo_inputs)
```

## Predictions and market shares in R

- `predictions` is now a matrix with one row per observation and one column per outcome
- These contain the predicted probabilities for each observation, based on the estimation dataset

## Predictions and market shares in R

- Most often, you will want to make a prediction for a _counterfactual_ scenario, i.e. a change to the data
- This is kind of clunky in Apollo; you modify the database directly, and then re-run `apollo_validateInputs` and `apollo_prediction`

## Predictions and market shares in R

`predictions.R`

```{r}
#| echo: true
#| filename: prediction.R

# Now, make predictions in a counterfactual scenario
# First, we will give the original database a new name
original_database = database

# then, we will adjust the cost_air column to add a 25 pound tax
# any time air is available
database = mutate(
    original_database,
    cost_air=ifelse(av_air, cost_air + 25, cost_air)
    )
```

---

```{r}
#| echo: true
#| filename: prediction.R

# now that we have a new variable called "database," we run
# apollo_validateInputs again, and then apollo_probabilities
# apollo_validateInputs will always use the variable called
# "database"
apollo_inputs = apollo_validateInputs()
tax_predictions =
    apollo_prediction(model, apollo_probabilities, apollo_inputs)
```

---

```{r}
#| echo: true
#| filename: prediction.R

# now, we can use the two predictions to compute changes in market shares
# first, original market shares
orig_mktshares = apply(
    predictions[,c("car", "rail", "air", "bus")],
    2,
    mean
)
orig_mktshares
```

---

```{r}
#| echo: true
#| filename: prediction.R

# next, taxed market shares
tax_mktshares = apply(
    tax_predictions[,c("car", "rail", "air", "bus")],
    2,
    mean
)
tax_mktshares
```

---

```{r}
#| echo: true
#| filename: prediction.R

# and finally, their difference. Is this the change we
# expect to see?
tax_mktshares - orig_mktshares
```

## Exercise

- How would new rail infrastructure that reduces journey times 25% affect market shares?
    - Remember to restore original database, and run `apollo_validateInputs` every time you change the database!
- My solution in `prediction-answers.R`

## Answers

```{r}
#| echo: true
#| filename: prediction-answers.R

# adjust travel times
database = mutate(
    original_database,
    time_rail=time_rail*0.75
    )

# re-load inputs
apollo_inputs = apollo_validateInputs()
```

---

```{r}
#| echo: true
#| filename: prediction-answers.R

# Make predictions
fast_rail_predictions =
    apollo_prediction(model, apollo_probabilities, apollo_inputs)
```

---

```{r}
#| echo: true
#| filename: prediction-answers.R

# compute market shares
fast_rail_mktshares = apply(
    fast_rail_predictions[,c("car", "rail", "air", "bus")],
    2,
    mean
)
fast_rail_mktshares
```

---

```{r}
#| echo: true
#| filename: prediction-answers.R

# compute differences
# if you need to recalculate orig_mktshares, make sure
# you re-run apollo_validateInputs before calculating
fast_rail_mktshares - orig_mktshares
```

# Logit model estimation: maximum likelihood

- Unlike linear regression, there is no closed-form solution
    - i.e. one you can just calculate
- Instead, we use _maximum likelihood_
- We define a _likelihood function_ which tells us how likely we are to observe the data we have, given a set of coefficients

# Logit model estimation: maximum likelihood

- We then choose a set of coefficients, the _starting values_, and adjust them until we find the best fit---the maximum of the likelihood function

## Likelihood function for a discrete choice model

- The likelihood function for a discrete choice model is the joint probability of all the chosen values
- If you had three people, who chose car, car, and bus to get to work, likelihood is the probability that the first person chose car multiplied by the probability the second person chose car multiplied by the probability the third person chose bus

## Likelihood function for a discrete choice model: the math
- In math:
$$
\prod_n P(y_n | x_n)\\
= \prod_n \frac{e^{U_{y_n}}}{\sum_j e^{U_{j_n}}}
$$

## Likelihood function for a discrete choice model: the math
- This is a vanishingly small number
    - In our mode choice example, something like $10^{-440}$
- Generally too small to be represented in a computer
```{r}
#| echo: true
10^-440
```

## Likelihood function for a discrete choice model: the math

- Instead, computers use the logarithm of likelihood (log-likelihood)
$$
\mathrm{ln} \prod_n P(y_n | x_n)\\
= \sum_n \mathrm{ln} \frac{e^{U_{y_n}}}{\sum_j e^{U_{j_n}}}
$$
- In our example above, this is -1014

## Comparing logistic models to each other

- We can use the log-likelihood to compare two models using a likelihood-ratio test
- This only works if the two models are _nested_
    - That is, one is a subset of the other, or you can make one into the other by constraining parameters
    - Not to be confused with _nested logit models_ which use a different error structure

## Comparing logistic models to each other

- Likelihood ratio test statistic is
$$
-2(\ell_1 - \ell_2)
$$
where $\ell_1$ is the likelihood of the less flexible model and $\ell_2$ the more flexible model

## Comparing logistic models to each other

- This is $\chi^2$-distributed with degrees of freedom equal to the number of additional parameters in the more flexible model
- Don't need to remember order, just put them in the order that makes test statistic positive

## Comparing logistic models to each other

| Model | Log-likelihood |
|-------|----------------|
| Same in-vehicle time coefficient | -1020 |
| Different in-vehicle time coefficients | -1014.74 |
| Test statistic | 10.52 |
| Degrees of freedom | 3 |

## Comparing logistic regression models to each other

```{r}
#| echo: true

1 - pchisq(10.52, 3)
```

## Comparing logistic regreession models to each other with Apollo

- If we have given our models unique names and run `apollo_saveOutput`, Apollo can do the test for us

```{r}
#| echo: true

apollo_lrTest("Apollo_Mode_Choice", "Apollo_Mode_Choice_Flexible")
```

## Goodness of fit metrics for logistic regression models

- Unlike linear regression, there is no $R^2$ for a logistic regression
- We can compare multiple models using a likelihood-ratio test
- But what if we don't have multiple models?

## Goodness of fit metrics for logistic regression models

- We do have the log-likelihood with all coefficients at 0 [LL(0)], and with only ASCs [LL(C)]

```
LL(0)                            : -1170.86
LL(C)                            : -1085.14
LL(final)                        : -1020
```

## Goodness of fit metrics for logistic regression models

- Many authors have created pseudo-$R^2$ metrics based on how much the model improves loglikelihood relative to these "base" log-likelihoods
- Most common is probably McFadden's, $1 - \frac{\ell}{\ell_C}$
- Or McFadden's adjusted, $1 - \frac{\ell - K}{\ell_C}$ where $K$ is number of estimated coefficients, which attempts to correct for overfitting

## Goodness of fit metrics for logistic regression models

- These range from 0 to 1, like an $R^2$, with higher values being better fit
- They can be relative to log-likelihood at constants or log-likelihood at zero
    - Former is more like the $R^2$ you've seen in linear models, which is usually relative to the mean of $y$
- Anecdotally, pseudo-$R^2$ statistics tend to be fairly low

## Comparing coefficients of logistic regression models

- In general, you _can't directly compare coefficients from different logistic regressions_
- They may be scaled differently
- In a linear regression, the coefficients have the same scale as the dependent variable
- But in logistic regression, utility is scaleless

## How is the scale set in logistic regression?

- The scale of coefficients is arbitrary, but the larger the coefficients are the larger the variance of the error term must be to produce the same predictions
- Multinomial logistic regression has a "scale parameter" which controls the scale of the error and thus the scale of the coefficients, usually assumed to equal 1
- But if you add predictors to a model so that there is less unexplained variation, the scale of the error term is fixed, so scale of other coefficients will change

## Marginal effects

- One solution to this problem is to use _marginal effects_—the average change in probability for a unit change in an independent variable
- This has a scale - the probability scale
- The marginal effect of a variable depends on the value of that and all other variables due to nonlinearities
- Hence, the _average marginal effect_
    - Usually, the marginal effect averaged over the entire sample
    - Sometimes, the marginal effect at mean values for all covariates

## Marginal effects in Apollo

- Apollo doesn't have a function to directly calculate marginal effects
- But, we can use prediction function to calculate on our own
- Let's calculate the marginal effect of in-vehicle travel time by car on all modes

## Marginal effects in Apollo

- We'll add a small amount to `time_car` and recalculate probabilities
- We'll then divide the change by that small amount to estimate the marginal effect
- This is a basic finite-differences approximation of the marginal effect

---

`margins.R`

```{r}
#| echo: true
#| filename: margins.R

# Run this after running mode-choice-mnl-in-vehicle-answers.R and predictions.R

# First, we will add 0.01 to the in-vehicle travel time by car
database =
    mutate(original_database, time_car=ifelse(av_car, time_car + 0.01, time_car))

# re-read inputs
apollo_inputs = apollo_validateInputs()
```

---

```{r}
#| echo: true
#| filename: margins.R

meff_predictions =
    apollo_prediction(model, apollo_probabilities, apollo_inputs)
```

---

```{r}
#| echo: true
#| filename: margins.R

# now, we can compute the per-observation marginal effect
# We divide by 0.01 to scale the marginal effects to a unit
# change in the independent variable, because this is the
# amount we added above
obs_meff = (meff_predictions - predictions) / 0.01

# now, we average to get the average marginal effect
apply(obs_meff[,c("car", "bus", "rail", "air")], 2, mean)
```

## Interpreting marginal effects

- Increasing travel time by car has a large negative effect on probability of choosing car
- Users are diverted primarily to rail, to air and bus to a lesser extent
- These are in probability units, so we can compare between models
- They are small, but they are per additional minute of travel time
- These marginal effects are dependent on the distribution of covariates in our sample

## Considerations when using marginal effects

- Dummy variables - may want to perform prediction with all dummies set to zero and one, rather than adding 0.01 to a dummy variable
- May want to use weights if your data have them, even if model is unweighted
- Elasticities are also a possibility, computing relative change in probability for a relative change in variables

## Exercise

- Compute and interpret marginal effects for income
    - My solution: `margins-answers.R`

## Answers

```{r}
#| echo: true
#| filename: margins-answers.R

# Run this after running mode-choice-mnl-in-vehicle-answers.R and predictions.R

# First, we will add 0.01 to the income
database =
    mutate(original_database, income=ifelse(av_car, income + 0.01, income))

# re-read inputs
apollo_inputs = apollo_validateInputs()
```

---

```{r}
#| echo: true
#| filename: margins-answers.R
# now, do the predictions
meff_predictions =
    apollo_prediction(model, apollo_probabilities, apollo_inputs)
```

---

```{r}
#| echo: true
#| filename: margins-answers.R

# now, we can compute the per-observation marginal effect
# We divide by 0.01 to scale the marginal effects to a unit
# change in the independent variable, because this is the
# amount we added above
obs_meff = (meff_predictions - predictions) / 0.01

# now, we average to get the average marginal effect
apply(obs_meff[,c("car", "bus", "rail", "air")], 2, mean)
```

# Practical application of choice models

## Data acquisition

- Data acquisition is very difficult if you want to include attributes of the alternatives
    - You don't _have_ to include attributes of alternatives, depends on your research question
- You need information not only on people did do, but what they could have done but chose not to

## Data acquisition

- One option is to do stated-preference surveys
- You can include _choice experiments_ where you present aspects of alternatives and ask respondents to choose
- Then you have all the alternative attributes
- But you still need to make sure they're reasonable, and standard stated-preference caveats apply (e.g. social desirability bias)

## Data acquisition

- For revealed preference, you need to come up with alternative attributes yourself
- In transport, we often use trip planning software to do this (e.g. Google Maps, OSRM, r5r)

## Pitfalls of _Apollo_

- Apollo works with global variables in R and expects some variables to have specific names
    - e.g. `database`
- This means that settings and data may "leak" between models if you don't clear your environment between estimations

# Independence of irrelevant alternatives

- When the utility of one alternative is increased, the probabilities of the other alternatives decrease in proportion to their probabilities
    - And vice-versa
    - Similarly when an alternative is added or removed

## The red bus/blue bus problem

- Suppose you have a model of mode choice, with two alternatives: driving and a red bus
- One individual has a 50% probability of choosing each alternative
- Suppose you paint half the buses red but don't change anything about the service

## The red bus/blue bus problem

- You'd expect this individual to now have probabilities 25% red bus, 25% blue bus, and 50% drive
- But, half of the probability has to come from each other alternative
- So, if blue bus has 25% probability, existing choices must all reduce by the same factor
- Red bus: 50% * .75 = 37.5%
- Same for car

## Independence of irrelevant alternatives: the red bus/blue bus problem

- This is true at the individual level, not the level of market shares [@ben-akiva_discrete_1985, p. 109--11]

## Independence of irrelevant alternatives: the math

$$ \frac{\delta p(b)}{\delta U_r}$$
$$
= \frac{
    e^{U_b}}{
        e^{U_r} + e^{U_b} + e^{U_c}}
    \frac{\delta}{\delta U_r}
$$

$$
    = e^{U_b} \big[ ( e^{U_r} + e^{U_b} + e^{U_c} \big)^{-1} \frac{\delta}{\delta U_r} \big]
$$


## Questions?

# Nested logit model

## Motivation

- The independence of irrelevant alternatives property of MNL derives from the assumed error distribution
    - Which is also how the probability function is derived
- Nested logit allows correlation within "nests" of alternatives
- Often used in mode choice or joint choice

## Model form

```{mermaid}
flowchart LR
    mc[Mode choice]
    car[Car]
    air[Air]
    bus[Bus]
    train[Train]

    mc --> car
    mc --> air
    mc --> bus
    mc --> train

```

## Model form

```{mermaid}
flowchart LR
    mc[Mode choice]
    car[Car]
    air[Air]
    transit[Transit]
    bus[Bus]
    train[Train]

    mc --> car
    mc --> air
    mc --> transit
    transit --> bus
    transit --> train
```

## Model form

- Often used to represent hierarchical or joint choice
- Used when there are _shared unobserved attributes_ between alternatives
    - In the red bus/blue bus problem, attributes of the bus
- Does not have to, just represents correlation in error term between alternatives

## Nested logit: the math

$$
U_i = \alpha_i + \beta_{ix} x_i + \cdots + \epsilon_{nest} + \epsilon_{i}
$$

- $\epsilon_{nest}$ allows correlation of error terms at the nest level

## Why do correlated error terms solve the red bus/blue bus problem?

- Easier to reason through than to do the math
- Definition of a random-utility model is that whatever alternative has the highest utility is chosen
- Utility has a random component $\epsilon$, so whether an alternative has highest utility is probabilistic

## Why do correlated error terms solve the red bus/blue bus problem?

- Suppose we are modeling the probability of auto vs. red bus vs. blue bus, and the systematic utilities are all 0
- So whichever alternative has the highest random error will be chosen
- Suppose we draw the error terms at random from a hat containing numbers 1--10
- The probability that any one error term is the largest is 1/3

## Why do correlated error terms solve the red bus/blue bus problem?

- But suppose we think that the unobserved attributes of the red bus and blue bus are the same
- Then we will draw one number for cars, and the _same number twice_ for the red and blue buses
- Since the error terms for the buses are the same, there is now a 50% chance that car will have highest utility, and 50% that the buses will

## Nested logit: additional parameters

- The nested logit adds one additional parameter per nest, the _inclusive value_ parameter
- Also called $\theta$, $\lambda$, $\frac{\mu_m}{\mu_d}$, $\frac{1}{\mu_d}$, logsum parameter
- Inclusive value parameters define how much correlation there is in the alternatives within a nest

## Nested logit: interpreting the inclusive value parameter

- Inclusive value parameters _should_ be between 0 and 1 to align with utility theory
- Larger inclusive value parameters mean _less_ correlation between alternatives in that nest
- Inclusive value parameters of 1---same as multinomial logit

## Nested logit: caution

- In order to interpret coefficients from different nests relative to each other, you must use a random utility nested logit model (RUMNL)
- These normalize the coefficients in each nest to be comparable to each other, by dividing by the inclusive value parameter
- Non-normalized nested logit (NNNL) does not perform this normalization
- RUMNL is default in Apollo, NNNL is default in Stata

## Nested logit: caution

- Nested logit inclusive value parameters should be tested with a null hypothesis that they are 1, not 0
- Many statistical packages (including Apollo) don't do this
- Thus, t-values and p-values will be incorrect

## Nested logit in R

```{r}
#| include: false
clear()
```

```{r}
#| echo: true
#| filename: nested-logit-mode-choice.R

library(apollo)
library(tidyverse)

database = read_csv("data/modechoice_apollo.csv")

apollo_initialise()

apollo_control = list(
    modelName = "Nested_Mode_Choice",
    indivID="ID"
)
```

---

```{r}
#| echo: true
#| filename: nested-logit-mode-choice.R

apollo_beta = c(
    asc_air = 0,
    asc_bus = 0,
    asc_rail = 0,
    # leaving out an asc_car as base category
    b_cost = 0,
    b_access_time = 0,
    b_in_vehicle_time = 0,
    # income and party_size are individual level variable, so
    # must be different for different alternatives
    b_income_air = 0,
    b_income_bus = 0,
    b_income_rail = 0,
    # This is the "nesting parameter" which captures how much variation
    # occurs at each level
    lambda_shared = 1
)
```

---

```{r}
#| echo: true
#| filename: nested-logit-mode-choice.R

apollo_fixed = c()
apollo_inputs = apollo_validateInputs()
```

---

```{r}
#| echo: true
#| filename: nested-logit-mode-choice.R

apollo_probabilities = function(apollo_beta, apollo_inputs,
        functionality="estimate") {
    apollo_attach(apollo_beta, apollo_inputs)
    on.exit(apollo_detach(apollo_beta, apollo_inputs))

    P = list()

    # define utility functions
    V = list()
    # We can include cost and in-vehicle time here because
    # they vary over alternatives
    V[["car"]] = b_cost * cost_car +
        b_in_vehicle_time * time_car

    V[["air"]] = asc_air +
        b_cost * cost_air +
        b_in_vehicle_time * time_air +
        b_access_time * access_air +
        b_income_air * income

    V[["rail"]] = asc_rail +
        b_cost * cost_rail +
        b_in_vehicle_time * time_rail +
        b_access_time * access_rail +
        b_income_rail * income

    V[["bus"]] = asc_bus +
        b_cost * cost_bus +
        b_in_vehicle_time * time_bus +
        b_access_time * access_bus +
        b_income_bus * income

    ## Now, we specify the nesting structure. First, we tell Apollo what
    ## nests we are using and their inclusive value parameters.
    nlNests = c(root=1, shared=lambda_shared)

    nlStructure = list(
        root=c("car", "shared"),
        shared=c("rail", "bus", "air")
    )

    nl_settings = list(
        alternatives = c(car=1, air=3, rail=4, bus=2),
        avail = list(car=av_car, air=av_air, rail=av_rail, bus=av_bus),
        choiceVar = choice,
        utilities = V,
        nlNests = nlNests,
        nlStructure = nlStructure
    )

    P[["model"]] = apollo_nl(nl_settings, functionality)

    # For panel data, this multiplies observations for single individuals
    # together - no effect in multinomial logit but still required.
    P = apollo_panelProd(P, apollo_inputs, functionality)
    P = apollo_prepareProb(P, apollo_inputs, functionality)
    return(P)
}
```

---

```{r}
#| echo: true
#| filename: nested-logit-mode-choice.R

model =
    apollo_estimate(apollo_beta, apollo_fixed, apollo_probabilities, apollo_inputs)
```

---

```{r}
#| echo: true
#| filename: nested-logit-mode-choice.R

apollo_modelOutput(model)
```

---

```{r}
#| echo: true
#| filename: nested-logit-mode-choice.R

apollo_saveOutput(model)
```

## Likelihood-ratio tests of the nested logit model

- We can perform a likelihood-ratio test, since constraining the inclusive value parameter to 1 would be the same as a multinomial logit model

---

```{r}
#| echo: true
#| filename: nested-logit-mode-choice.R

apollo_lrTest("Nested_Mode_Choice", "Apollo_Mode_Choice")
```

# Mixed logit

## Mixed logit

- In multinomial logit and nested logit models, parameters are assumed to be constant across the population
- Mixed logit allows (a subset of) coefficients to vary across individuals

## Mixed logit as an alternative to nested logit

- By creating random coefficients that enter multiple utility functions as constants, correlations can be created
- Basically, using random coefficients as additional shared error terms

## Mixed logit

We might write our nested model above as

$$
U_{car} = X_{car}B_{car} + \epsilon_{car}
$$

$$
U_{bus} = X_{bus}B_{bus} + \mu'_{shared} + \epsilon_{bus}
$$

$$
U_{rail} = X_{rail}B_{rail} + \mu'_{shared} + \epsilon_{rail}
$$

$$
U_{air} = X_{air}B_{air} + \mu'_{shared} + \epsilon_{air}
$$

$\mu'_{shared}$ is a random value which acts as a common error term for the shared modes

## Mixed logit: probabilities

- The mixed logit probability is the same as the multinomial logit probability, but integrated over the random coefficients
- This is usually done through simulation
    - Random draws are taken from the coefficient distribution, the likelihood is calculated for each, and then they are averaged together

## Mixed logit

- Mixed logit can also have coefficients that vary randomly
- Common use is value of time - we know this varies a lot across the population 
- For more information on mixed logit models, see @train_discrete_2009 (free ebook available) and the Apollo manual

## Mixed logit in R


```{r}
#| include: false
clear()
```

```{r}
#| echo: true
#| filename: mixed-logit-mode-choice.R

library(apollo)
library(tidyverse)

database = read_csv("data/modechoice_apollo.csv")

apollo_initialise()

apollo_control = list(
    modelName = "Mixed_Mode_Choice",
    indivID="ID",
    mixing = T
)
```

---

```{r}
#| echo: true
#| filename: mixed-logit-mode-choice.R

apollo_beta = c(
    asc_air = 0,
    asc_bus = 0,
    asc_rail = 0,
    # leaving out an asc_car as base category
    b_cost = 0,
    b_access_time = 0,
    b_in_vehicle_time = 0,
    # income and party_size are individual level variable, so
    # must be different for different alternatives
    b_income_air = 0,
    b_income_bus = 0,
    b_income_rail = 0,
    # This is the standard deviation of the shared error component
    # random term, which will be normally distributed.
    sd_shared = 1
)
```

---

## Defining draws

- We need to tell Apollo what random variable we have
- Since log-likelihood is simulated, these are called "draws"
- Halton draws are common since they provide good distribution
- Most often in panel data, draws vary at the individual level
    - i.e. an individual has the same random coefficient for all choices

---

```{r}
#| echo: true
#| filename: mixed-logit-mode-choice.R

apollo_draws = list(
    interDrawsType="halton",
    # number of draws - more is slower but more accurate
    interNDraws=500,
    # no uniformly-distributed random variables
    interUnifDraws=c(),
    # one normally-distributed random variable
    interNormDraws=c("draws_shared_mode_error")
    # can also use intraNDraws etc. for intra-individual draws
    # (less common)
)
```

---

## Defining random coefficients

- Based on the draws, we then define an `apollo_randCoeff` function that transforms them as needed to the desired form

---

```{r}
#| echo: true
#| filename: mixed-logit-mode-choice.R

apollo_randCoeff = function (apollo_beta, apollo_inputs) {
    randcoeff = list()
    # error term has mean zero, so we multiply by standard deviation
    # but do not add an offset
    # anything we add to this list will be available in apollo_probabilities
    randcoeff[["shared_mode_error"]] = sd_shared * draws_shared_mode_error

    return(randcoeff)
}

```


```{r}
#| echo: true
#| filename: mixed-logit-mode-choice.R

apollo_fixed = c()
apollo_inputs = apollo_validateInputs()
```

---

```{r}
#| echo: true
#| filename: mixed-logit-mode-choice.R

apollo_probabilities = function(apollo_beta, apollo_inputs,
        functionality="estimate") {
    apollo_attach(apollo_beta, apollo_inputs)
    on.exit(apollo_detach(apollo_beta, apollo_inputs))

    P = list()

    # define utility functions
    V = list()
    # We can include cost and in-vehicle time here because
    # they vary over alternatives
    V[["car"]] = b_cost * cost_car +
        b_in_vehicle_time * time_car

    V[["air"]] = asc_air +
        b_cost * cost_air +
        b_in_vehicle_time * time_air +
        b_access_time * access_air +
        b_income_air * income +
        shared_mode_error

    V[["rail"]] = asc_rail +
        b_cost * cost_rail +
        b_in_vehicle_time * time_rail +
        b_access_time * access_rail +
        b_income_rail * income +
        shared_mode_error

    V[["bus"]] = asc_bus +
        b_cost * cost_bus +
        b_in_vehicle_time * time_bus +
        b_access_time * access_bus +
        b_income_bus * income +
        shared_mode_error

    # mathematically, this is still a multinomial logit model,
    # just integrated over our random variables
    mnl_settings = list(
        alternatives = c(car=1, air=3, rail=4, bus=2),
        avail = list(car=av_car, air=av_air, rail=av_rail, bus=av_bus),
        choiceVar = choice,
        utilities = V
    )

    P[["model"]] = apollo_mnl(mnl_settings, functionality)

    # we need to average the draws together. Because of the structure of the
    # mixed logit model, intra-individual draws need to be averaged before
    # joint choices in a panel are multiplied together, while inter-individual
    # need to be averaged after. If we had intra-individual draws, the line below
    # would average them. But since we don't, it's commented out.
    # P = apollo_avgIntraDraws(P, apollo_inputs, functionality)

    # For panel data, this multiplies observations for single individuals
    # together - no effect in multinomial logit but still required.
    P = apollo_panelProd(P, apollo_inputs, functionality)

    # now average across inter-individual draws
    P = apollo_avgInterDraws(P, apollo_inputs, functionality)

    P = apollo_prepareProb(P, apollo_inputs, functionality)
    return(P)
}
```

---

```{r}
#| echo: true
#| filename: mixed-logit-mode-choice.R

model =
    apollo_estimate(apollo_beta, apollo_fixed, apollo_probabilities, apollo_inputs)
```

---

```{r}
#| echo: true
#| filename: mixed-logit-mode-choice.R

apollo_modelOutput(model)
```

---

```{r}
#| echo: true
#| filename: mixed-logit-mode-choice.R

apollo_saveOutput(model)
```

## Likelihood-ratio test for mixed logit

- Cannot compare to nested logit (why?)
 . . .
  - Models are non-nested, cannot reduce this mixed logit model to nested logit
- Can compare to multinomial logit (with what constraint?)
 . . . 
  - Constrain standard deviation to zero

---

```{r}
apollo_lrTest("Mixed_Mode_Choice", "Apollo_Mode_Choice")
```

## Interpreting mixed logit models

- Error components model: standard deviations of error terms and their significance is proportional to correlation between alternatives
    - opposite of nested logit, where smaller inclusive value parameters mean more correlation
- Can also have random coefficients
    - Usually a mean is added to the coefficients in this case
    - Often used for value of time

## Interpreting mixed logit models
- Be careful with valuation
    - Ratio of normally distributed coefficients is Cauchy distributed
    - Known as a "pathological" distribution - no mean
    - Probably not economically consistent; even Jeff Bezos doesn't have infinite value of time

## Questions and contact

Matt Bhagat-Conway

[mwbc@unc.edu](mailto:mwbc@unc.edu)

[&#64;mattwigway](https://twitter.com/mattwigway)

## References

::: {#refs}
:::